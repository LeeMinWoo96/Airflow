{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 537577 entries, 0 to 537576\n",
      "Data columns (total 12 columns):\n",
      "User_ID                       537577 non-null int64\n",
      "Product_ID                    537577 non-null object\n",
      "Gender                        537577 non-null object\n",
      "Age                           537577 non-null object\n",
      "Occupation                    537577 non-null int64\n",
      "City_Category                 537577 non-null object\n",
      "Stay_In_Current_City_Years    537577 non-null object\n",
      "Marital_Status                537577 non-null int64\n",
      "Product_Category_1            537577 non-null int64\n",
      "Product_Category_2            370591 non-null float64\n",
      "Product_Category_3            164278 non-null float64\n",
      "Purchase                      537577 non-null int64\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 49.2+ MB\n",
      "None\n",
      "Purchase              1.000000\n",
      "Occupation            0.022176\n",
      "User_ID               0.005239\n",
      "Marital_Status        0.000299\n",
      "Product_Category_3   -0.021352\n",
      "Product_Category_2   -0.209204\n",
      "Product_Category_1   -0.313336\n",
      "Name: Purchase, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 430061 entries, 110911 to 149503\n",
      "Data columns (total 11 columns):\n",
      "User_ID                       430061 non-null int64\n",
      "Product_ID                    430061 non-null object\n",
      "Gender                        430061 non-null object\n",
      "Age                           430061 non-null object\n",
      "Occupation                    430061 non-null int64\n",
      "City_Category                 430061 non-null object\n",
      "Stay_In_Current_City_Years    430061 non-null object\n",
      "Marital_Status                430061 non-null int64\n",
      "Product_Category_1            430061 non-null int64\n",
      "Product_Category_2            296577 non-null float64\n",
      "Product_Category_3            131321 non-null float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 39.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 작성자 : 이민우\n",
    "# 작성일 : 20181101\n",
    "# 프로그램설명 : 머신러닝을 이용한 가격예측\n",
    "import os \n",
    "import tarfile\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin): # 데이터프레임을 다룰수 없어 numpy 배열로 전환하는 클래스\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values # 주어진 attribute_name에 해당하는 값을 반환 \n",
    "    \n",
    "    \n",
    "def load_housing_data(filename, test_path = \"datasets\"): # 주어진 filename 을 읽는 함수\n",
    "    csv_path = os.path.join(test_path,filename)\n",
    "    return pd.read_csv(csv_path)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # 주어진 링크에서 all.zip 을 다운받아 압축을 푼 후 진행하였습니다.\n",
    "    \n",
    "    All_set = load_housing_data(\"who_suicide_statics\")\n",
    "\n",
    "    \n",
    "    print(All_set.info())\n",
    "    \n",
    "    #All_set[\"Purchase\"].hist(bins = 16)\n",
    "    \n",
    "    # 카테고리 개수 제한\n",
    "    All_set[\"st\"] = np.ceil(All_set[\"Purchase\"]/5000)\n",
    "    \n",
    "    All_set[\"st\"].where(All_set[\"st\"] < 4, 4, inplace = True)\n",
    "    \n",
    "    All_set[\"st\"].hist(bins = 16)\n",
    "    \n",
    "    train_set, test_set = train_test_split(All_set, test_size=0.2, random_state=42, stratify=All_set[\"st\"])\n",
    "    \n",
    "    for set_ in (train_set, test_set):\n",
    "        set_.drop(\"st\", axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "    train = train_set.drop(\"Purchase\", axis=1)\n",
    "    train_labels = train_set[\"Purchase\"].copy()\n",
    "    \n",
    "    train_copy = train_set.copy()\n",
    "  \n",
    "    corr = train_copy.corr()\n",
    "    print(corr[\"Purchase\"].sort_values(ascending = False))\n",
    "    \n",
    "    print(train.info())\n",
    "    \n",
    "    \n",
    "    \n",
    "    num_attr = train.select_dtypes(exclude = 'object').columns.values.tolist()# object 형 제외 즉 수치형 특성의 column 값을 리스트로 반환\n",
    "    cat_attr = train.select_dtypes(include = 'object').columns.values.tolist()# object 형 즉 범주형 특성의 column 값을 리스트로 반환\n",
    "    templist = []\n",
    "  \n",
    "  \n",
    "    # 수치형 파이프라인 \n",
    "    num_pipeline = Pipeline([\n",
    "                            ('selector', DataFrameSelector(num_attr)),\n",
    "                            ('imputer', Imputer(strategy=\"median\")),\n",
    "                            ('std_scaler', StandardScaler()),\n",
    "                            ])\n",
    "    # 범주형 파이프라인 \n",
    "    cat_pipeline = Pipeline([\n",
    "                            ('selector', DataFrameSelector(cat_attr)),\n",
    "                            ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "                            ])\n",
    "    # 수치형 + 범주형파이프라인 \n",
    "    \n",
    "    full_pipeline = FeatureUnion(transformer_list=[\n",
    "            (\"num_pipeline\", num_pipeline),\n",
    "            (\"cat_pipeline\", cat_pipeline),\n",
    "        ])\n",
    " \n",
    "    # 최종 정제된 데이터 \n",
    "    train_prepared = full_pipeline.fit_transform(train)\n",
    "    \"\"\"\n",
    "    # 선형모델 rmse 실험 \n",
    "    lin_reg = LinearRegression() # 선형모델 생성 \n",
    "    lin_reg.fit(train_prepared,train_labels) # 학습 \n",
    "    lin_prediction = lin_reg.predict(train_prepared) # 선형모델로 예측한 값 \n",
    "    lin_mse = mean_squared_error(train_labels, lin_prediction) # 예측한 값과 레이블의 차이\n",
    "    lin_rmse = np.sqrt(lin_mse) # 차이에 root \n",
    "    print(\"선형모델 rmse : \",lin_rmse)\n",
    "    \n",
    "    # 결정트리 rmse 실험 \n",
    "    tre_reg = DecisionTreeRegressor() # 결정트리모델 생성 \n",
    "    tre_reg.fit(train_prepared,train_labels) # 학습 \n",
    "    tre_prediction = tre_reg.predict(train_prepared) # 결정트리로 예측한 값 \n",
    "    tre_mse = mean_squared_error(train_labels, tre_prediction) # 예측한 값과 레이블의 차이 \n",
    "    tre_rmse = np.sqrt(tre_mse) \n",
    "    print(\"결정트리 rmse : \",tre_rmse)\n",
    "    \n",
    "    # 랜덤포레스트모델 (앙상블 기법)\n",
    "    fo_reg = RandomForestRegressor() # 모델 생성 \n",
    "    fo_reg.fit(train_prepared, train_labels) # 모델 학습 \n",
    "    fo_prediction = fo_reg.predict(train_prepared) # 모델로 예측값 도출\n",
    "    fo_mse = mean_squared_error(train_labels, fo_prediction) # mse 값 \n",
    "    fo_rmse = np.sqrt(tre_mse) # rmse 값 \n",
    "    print(\"랜덤모델 rmse : \",fo_rmse)\n",
    "    \n",
    "    \n",
    "    # 교차검증을 사용한 평가. \n",
    "    # mse 가 아닌 nmse 를 사용 \n",
    "    # 선형모델의 경우 2, 결정트리,랜덤포레스트 10 의 cv 를 사용 \n",
    "    # 선형모델의 경우 교차검증 사용시 큰 값의 숫자가 출력되는데 이유는 찾지 못했습니다. \n",
    "    \n",
    "    scores = cross_val_score(lin_reg, train_prepared, train_labels,scoring = \"neg_mean_squared_error\", cv = 2)\n",
    "    lin_rmse_score = np.sqrt(-scores)\n",
    "    display_score(lin_rmse_score)\n",
    "    \n",
    "    scores = cross_val_score(tre_reg,train_prepared, train_labels,scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "    tre_rmse_score = np.sqrt(-scores)\n",
    "    display_score(tre_rmse_score)\n",
    "    \n",
    "    scores = cross_val_score(fo_reg,train_prepared, train_labels,scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "    fo_rmse_score = np.sqrt(-scores)\n",
    "    display_score(fo_rmse_score)\n",
    "    \n",
    "    \n",
    "    #모델이 정해진 후에 그에따른 가장 최적의 파라미터를 찾는다.\n",
    "    \n",
    "    # 그리드 탐색 총 90번의 탐색 진행 \n",
    "    param_grid = [\n",
    "        {'n_estimators':[3,10,30],'max_features':[2,4,6,8]},\n",
    "        {'bootstrap':[False],'n_estimators':[3,10],'max_features':[2,3,4]},    \n",
    "    ]\n",
    "    \n",
    "    grid_search = GridSearchCV(fo_reg, param_grid, cv = 5, scoring = 'neg_mean_squared_error',\n",
    "                                return_train_score = True)\n",
    "    grid_search.fit(train_prepared, train_labels)\n",
    "    \n",
    "    #랜덤 탐색 랜덤으로 탐색 진행 (크기가 클수록 효과적)\n",
    "   \n",
    "    param_dis = {\n",
    "        'n_estimators':randint(low =1, high = 200),\n",
    "        'max_features':randint(low = 1, high = 8),\n",
    "    }\n",
    "    \n",
    "    rnd_search = RandomizedSearchCV(fo_reg,param_distributions = param_dis,\n",
    "                                    n_iter = 10, cv = 5, scoring = 'neg_mean_squared_error',\n",
    "                                    random_state = 42, n_jobs = -1)\n",
    "    \n",
    "    rnd_search.fit(train_prepared, train_labels)\n",
    "    \n",
    "    \n",
    "    cvres = grid_search.cv_results_ # 그리드 탐색의 결과 \n",
    "        \n",
    "    print('-------------- 그리드 탐색 ---------------')\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"],cvres[\"params\"]): # score 와 params 출력\n",
    "        print(np.sqrt(-mean_score),params)\n",
    "        \n",
    "\n",
    "    cvres = rnd_search.cv_results_ # 랜덤 탐색의 결과\n",
    "    \n",
    "    print('')\n",
    "    print('-------------- 랜덤 탐색 ---------------')\n",
    "        \n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"],cvres[\"params\"]): # score 와 params 출력\n",
    "        print(np.sqrt(-mean_score),params)\n",
    "    \n",
    "    \n",
    "    final_model = rnd_search.best_estimator_ # ppt 는 grid search로 찾은 파라미터를 사용하였지만\n",
    "    # 저는 random search 로 찾은 파라미터를 사용하였습니다. \n",
    "    \n",
    " \n",
    "    \n",
    "    test = test_set.copy() # 최종 test set \n",
    "    test['SalePrice'] = sample_set['SalePrice'] # test set 에 정답 레이블을 매칭시켜준다.\n",
    "    \n",
    "    \n",
    "    num_attr = test.select_dtypes(exclude = 'object').columns.values.tolist() # 수치형 특성들만 리스트로 반환\n",
    "    cat_attr = test.select_dtypes(include = 'object').columns.values.tolist() # 범부형 특성들만 리스트로 반환\n",
    "    templist = []\n",
    "    IDlist = []\n",
    "    \n",
    "    for temp in cat_attr:\n",
    "        su = test[temp].isnull().sum() # 결측값의 합 \n",
    "        \n",
    "        if su> 500: # 결측값의 값이 500 이상 \n",
    "            test = test.drop(temp, axis = 1) # 이면 쓸모 없는 특성이라 생각하고 특성  drop\n",
    "            templist.append(temp)\n",
    "    \n",
    "    for temp in templist:\n",
    "        cat_attr.remove(temp) # drop 된 특성들을 범주형 특성리스트에서도 지운다. \n",
    "        \n",
    "    \n",
    "        \n",
    "    test=test.dropna(subset = cat_attr) # 마지막으로 범주형 특성중에 결측값이 있는 샘플 제거 \n",
    "   \n",
    "    test_labels = test['SalePrice'].copy() # 정답 레이블 분리 \n",
    "    test = test.drop('SalePrice',axis = 1)\n",
    "    \n",
    "    print(cat_attr)\n",
    "    # train_set 에서 데이터 정제를 하던 중 없어지는 특성이 있어 인코딩 할때 문제가 발생되는데\n",
    "    # train.csv 파일에 다른 내용은 같고 없\n",
    "    test_prepared = full_pipeline.transform(test) # 데이터 정제 \n",
    "   \n",
    "    final_predictions = final_model.predict(test_prepared) #최종 모델로 예측 \n",
    "    \n",
    "    final_mse = mean_squared_error(test_labels, final_predictions)\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "    \n",
    "    print(\"최종 rmse\", final_rmse) # 최종 rmse 값 일반적으로 교차검증을 사용할때보다 크게나옴 \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']\n",
      "[1.61561562]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[2]\n",
      "[[6.38014896e-07 5.74929995e-02 9.42506362e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlwor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 작성자 : 이민우\n",
    "# 로지스틱 회귀 실습\n",
    "\n",
    "from sklearn import datasets # iris 데이터 셋 \n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱 회귀\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iris = datasets.load_iris() # 데이터 로드 \n",
    "    # 4개의 특징 \n",
    "    # 클래스당 150개 샘플\n",
    "    print(list(iris.keys()))\n",
    "   \n",
    "    \n",
    "   # print(iris.DESCR)\n",
    "    X = iris[\"data\"][:,3:] # 꽃잎 넓이로 판별\n",
    "    y = (iris[\"target\"]==2).astype(np.int) # iris-virginica 이면 1 아니면 0\n",
    "    \n",
    "    log_reg = LogisticRegression() # 로지스틱 회귀 모델 \n",
    "    log_reg.fit(X,y) # 학습 \n",
    "    \n",
    "    X_new = np.linspace(0,3,1000).reshape(-1,1)\n",
    "    y_proba = log_reg.predict_proba(X_new) # 조건부 확률 계산\n",
    "    decision_boundary = X_new[y_proba[:,1] >= 0.5][0] # 확률이 50%가 되는 결정 경계\n",
    "    \n",
    "    #print(decision_boundary)\n",
    "    \n",
    "    print(log_reg.predict([[1.7],[1.5]])) # 1.7 일땐 True 1.5 일땐 false 로 판별\n",
    "    \n",
    "    X = iris[\"data\"][:,(2,3)] # petal Length, petal width\n",
    "    # 꽃잎 너비와 길이 두개로 판별\n",
    "    \n",
    "    y = (iris[\"target\"] == 2).astype(np.int) # iris-virginica 이면 1 아니면 0\n",
    "    \n",
    "    log_reg = LogisticRegression(solver = 'liblinear', C = 10**10, random_state =42)\n",
    "    log_reg.fit(X,y)\n",
    "    print(log_reg.predict([[4.0,1.0],[6.0,2.5]]))\n",
    "    #너비 4.9, 길이 1.0 과 6.0, 2.5 예측 결과 0과 1\n",
    "    \n",
    "    \n",
    "    X = iris[\"data\"][:,(2,3)]\n",
    "    y = iris[\"target\"]\n",
    "    \n",
    "    # 소프트 맥스 회귀( 다항 로지스틱 회귀) \n",
    "    # 로지스틱 회귀를 여러개의 이진 분류기를 훈련시켜 연결하는 방식이 아니라\n",
    "    # 직접 다중 클래스를 지원하도록 일반화\n",
    "    \n",
    "    softmax_reg = LogisticRegression(multi_class = \"multinomial\", solver =\"lbfgs\", C = 10, random_state = 42)\n",
    "    # multi_class 를 multinomial 로 바꿈으로 소프트맥스 회귀를 사용가능하다.\n",
    "    # solver 매개변수에 지원하는 알고리즘을 지정해야한다.\n",
    "    # 대부분의 solver 매개변수의 기본값은 adam 이다 특징은 잘 작동하지만 \n",
    "    # 스케일에 민감하다. (스케일링 중요)\n",
    "    # 다른 하나는 sgd 이다 딥러닝에서 주로 사용되며 다른 여러 매개변수와\n",
    "    # 함께 튜닝하여 최적의 결과를 도출한다.\n",
    "    # lbfgs는 안정적이나 규모가 큰 모델이나 데이터셋에서는 시간이 오래걸린다.\n",
    "    softmax_reg.fit(X,y)\n",
    "    \n",
    "    print(softmax_reg.predict([[5,2]])) # 클레스 2라고 출력 \n",
    "    # (Iris-Setosa, Iris-Virginica, Iris-Versicolor)\n",
    "    print(softmax_reg.predict_proba([[5,2]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
